{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyNZPGV9zd14OH2lLLh1GJXR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mericamp97/-greenhouse-job-description-scraper-chrome-extension/blob/main/Bert_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wk8oU4QEU_xg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xjd6RHg-XRc9",
        "outputId": "5b406647-01e5-41cc-f194-5ee70b081091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUoorXsmW5eJ",
        "outputId": "e17947e6-a7e9-468f-de11-f34f6bdae50d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path_profile = '/content/drive/My Drive/BT5153_Kaggle/profile.csv'\n",
        "profile = pd.read_csv(file_path_profile)\n",
        "file_path_trx = '/content/drive/My Drive/BT5153_Kaggle/trx_data.csv'\n",
        "trx = pd.read_csv(file_path_trx)\n",
        "file_path_trx = '/content/drive/My Drive/BT5153_Kaggle/train_label.csv'\n",
        "train_label = pd.read_csv(file_path_trx)"
      ],
      "metadata": {
        "id": "wVwDNnQYVPfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Engineering"
      ],
      "metadata": {
        "id": "ls8_tBqoVcsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trx['transaction_time'] = pd.to_datetime(trx['transaction_time'])\n",
        "\n",
        "# Pre-calculate flags for each transaction type and asset type\n",
        "trx['sell_flag'] = (trx['transaction_type'] == 'SELL').astype(int)\n",
        "trx['buy_flag'] = (trx['transaction_type'] == 'BUY').astype(int)\n",
        "\n",
        "# For asset types, you can use get_dummies for a one-hot encoding approach\n",
        "asset_type_dummies = pd.get_dummies(trx['asset_type'])\n",
        "trx = pd.concat([trx, asset_type_dummies], axis=1)\n",
        "\n",
        "# Now group by 'user_id' and sum up the flags and dummies\n",
        "agg_dict = {\n",
        "    'sell_flag': 'sum',\n",
        "    'buy_flag': 'sum',\n",
        "    'crypto': 'sum',\n",
        "    'gold': 'sum',\n",
        "    'fx': 'sum',\n",
        "    'gss': 'sum',\n",
        "    'stock_index': 'sum',\n",
        "    'idss': 'sum',\n",
        "    'mfund': 'sum'\n",
        "}\n",
        "\n",
        "# Adding total transactions as count of rows\n",
        "agg_dict['user_id'] = 'count'\n",
        "\n",
        "trx_counts = trx.groupby('user_id').agg(agg_dict).rename(columns={'user_id': 'total_transactions'})\n",
        "\n",
        "# Let's check the first few rows of the optimized trx_counts\n",
        "print(trx_counts.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8VM_WvDVPpZ",
        "outputId": "2ae2d6e8-dcc1-4bde-8c36-81d8813325fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         sell_flag  buy_flag  crypto  gold  fx  gss  stock_index  idss  mfund  \\\n",
            "user_id                                                                         \n",
            "0                0         3       2     1   0    0            0     0      0   \n",
            "1                0         9       8     1   0    0            0     0      0   \n",
            "2                1         0       0     1   0    0            0     0      0   \n",
            "3                0         6       4     0   1    1            0     0      0   \n",
            "4                2         1       0     2   0    0            0     0      1   \n",
            "\n",
            "         total_transactions  \n",
            "user_id                      \n",
            "0                         3  \n",
            "1                         9  \n",
            "2                         1  \n",
            "3                         6  \n",
            "4                         3  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trx[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "klk2fB9akHwx",
        "outputId": "5278fd65-bd4f-485b-b76e-308211403a10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         transaction_time  user_id transaction_type asset_type         gtv  \\\n",
              "0 2022-04-01 00:00:01.382    59345             SELL     crypto  571.296429   \n",
              "1 2022-04-01 00:00:02.218    76970              BUY     crypto   26.780357   \n",
              "2 2022-04-01 00:00:04.892    81533              BUY     crypto    8.916071   \n",
              "3 2022-04-01 00:00:05.002     2767             SELL     crypto  685.591071   \n",
              "4 2022-04-01 00:00:05.769    34438             SELL     crypto   81.142857   \n",
              "5 2022-04-01 00:00:07.239    79831              BUY     crypto  221.975000   \n",
              "6 2022-04-01 00:00:07.762    69419             SELL     crypto  244.057143   \n",
              "7 2022-04-01 00:00:08.210    74868             SELL     crypto  240.985714   \n",
              "8 2022-04-01 00:00:08.309     2880              BUY     crypto  362.433929   \n",
              "9 2022-04-01 00:00:08.724    39775              BUY     crypto   20.625000   \n",
              "\n",
              "   sell_flag  buy_flag  crypto  fx  gold  gss  idss  mfund  stock_index  \n",
              "0          1         0       1   0     0    0     0      0            0  \n",
              "1          0         1       1   0     0    0     0      0            0  \n",
              "2          0         1       1   0     0    0     0      0            0  \n",
              "3          1         0       1   0     0    0     0      0            0  \n",
              "4          1         0       1   0     0    0     0      0            0  \n",
              "5          0         1       1   0     0    0     0      0            0  \n",
              "6          1         0       1   0     0    0     0      0            0  \n",
              "7          1         0       1   0     0    0     0      0            0  \n",
              "8          0         1       1   0     0    0     0      0            0  \n",
              "9          0         1       1   0     0    0     0      0            0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4a710763-2515-41cf-bc34-79290aea9fe9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>transaction_time</th>\n",
              "      <th>user_id</th>\n",
              "      <th>transaction_type</th>\n",
              "      <th>asset_type</th>\n",
              "      <th>gtv</th>\n",
              "      <th>sell_flag</th>\n",
              "      <th>buy_flag</th>\n",
              "      <th>crypto</th>\n",
              "      <th>fx</th>\n",
              "      <th>gold</th>\n",
              "      <th>gss</th>\n",
              "      <th>idss</th>\n",
              "      <th>mfund</th>\n",
              "      <th>stock_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-04-01 00:00:01.382</td>\n",
              "      <td>59345</td>\n",
              "      <td>SELL</td>\n",
              "      <td>crypto</td>\n",
              "      <td>571.296429</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-04-01 00:00:02.218</td>\n",
              "      <td>76970</td>\n",
              "      <td>BUY</td>\n",
              "      <td>crypto</td>\n",
              "      <td>26.780357</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-04-01 00:00:04.892</td>\n",
              "      <td>81533</td>\n",
              "      <td>BUY</td>\n",
              "      <td>crypto</td>\n",
              "      <td>8.916071</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-04-01 00:00:05.002</td>\n",
              "      <td>2767</td>\n",
              "      <td>SELL</td>\n",
              "      <td>crypto</td>\n",
              "      <td>685.591071</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-04-01 00:00:05.769</td>\n",
              "      <td>34438</td>\n",
              "      <td>SELL</td>\n",
              "      <td>crypto</td>\n",
              "      <td>81.142857</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2022-04-01 00:00:07.239</td>\n",
              "      <td>79831</td>\n",
              "      <td>BUY</td>\n",
              "      <td>crypto</td>\n",
              "      <td>221.975000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2022-04-01 00:00:07.762</td>\n",
              "      <td>69419</td>\n",
              "      <td>SELL</td>\n",
              "      <td>crypto</td>\n",
              "      <td>244.057143</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2022-04-01 00:00:08.210</td>\n",
              "      <td>74868</td>\n",
              "      <td>SELL</td>\n",
              "      <td>crypto</td>\n",
              "      <td>240.985714</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2022-04-01 00:00:08.309</td>\n",
              "      <td>2880</td>\n",
              "      <td>BUY</td>\n",
              "      <td>crypto</td>\n",
              "      <td>362.433929</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2022-04-01 00:00:08.724</td>\n",
              "      <td>39775</td>\n",
              "      <td>BUY</td>\n",
              "      <td>crypto</td>\n",
              "      <td>20.625000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a710763-2515-41cf-bc34-79290aea9fe9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4a710763-2515-41cf-bc34-79290aea9fe9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4a710763-2515-41cf-bc34-79290aea9fe9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8fef2460-2386-4101-b7b5-ac36e976fec8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8fef2460-2386-4101-b7b5-ac36e976fec8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8fef2460-2386-4101-b7b5-ac36e976fec8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"trx[:10]\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"transaction_time\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2022-04-01 00:00:01.382000\",\n        \"max\": \"2022-04-01 00:00:08.724000\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"2022-04-01 00:00:08.309000\",\n          \"2022-04-01 00:00:02.218000\",\n          \"2022-04-01 00:00:07.239000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30631,\n        \"min\": 2767,\n        \"max\": 81533,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          2880,\n          76970,\n          79831\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"transaction_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"BUY\",\n          \"SELL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"asset_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"crypto\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gtv\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 234.62912035935898,\n        \"min\": 8.91607142857143,\n        \"max\": 685.5910714285714,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          362.43392857142857\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sell_flag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"buy_flag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"crypto\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fx\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gold\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gss\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"idss\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mfund\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stock_index\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculate GTV statistics\n",
        "gtv_stats = trx.groupby('user_id')['gtv'].agg(['mean', 'median', 'max', 'min']).rename(columns={\n",
        "    'mean': 'average_GTV',\n",
        "    'median': 'median_GTV',\n",
        "    'max': 'max_GTV',\n",
        "    'min': 'min_GTV'\n",
        "})\n",
        "\n",
        "gtv_stats['max_minus_median_GTV'] = gtv_stats['max_GTV'] - gtv_stats['median_GTV']\n",
        "\n",
        "# Display the first few rows of the modified GTV stats\n",
        "print(gtv_stats.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8Tns4AtVPwa",
        "outputId": "de171a38-7e0d-4471-f28f-be49241313fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         average_GTV  median_GTV      max_GTV     min_GTV  \\\n",
            "user_id                                                     \n",
            "0          14.481548   16.669643    17.848214    8.926786   \n",
            "1         270.889286   89.285714  1679.078571   89.282143   \n",
            "2         162.785714  162.785714   162.785714  162.785714   \n",
            "3         564.834226  535.711607   714.282143  442.687500   \n",
            "4          19.985119   16.666071    26.750000   16.539286   \n",
            "\n",
            "         max_minus_median_GTV  \n",
            "user_id                        \n",
            "0                    1.178571  \n",
            "1                 1589.792857  \n",
            "2                    0.000000  \n",
            "3                  178.570536  \n",
            "4                   10.083929  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate average time between transactions in minutes\n",
        "trx.sort_values(by=['user_id', 'transaction_time'], inplace=True)\n",
        "trx['time_diff'] = trx.groupby('user_id')['transaction_time'].diff().dt.total_seconds() / 60\n",
        "avg_time_diff = trx.groupby('user_id')['time_diff'].mean().to_frame('avg_time_between_transactions')\n",
        "\n",
        "print(avg_time_diff[:5])\n",
        "\n",
        "print(avg_time_diff['avg_time_between_transactions'].max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhAKqFHvVnT-",
        "outputId": "a35ada27-7176-4364-9df4-c31ecefed5bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         avg_time_between_transactions\n",
            "user_id                               \n",
            "0                            25.095825\n",
            "1                          8375.102619\n",
            "2                                  NaN\n",
            "3                          8358.912597\n",
            "4                          2659.806083\n",
            "86359.67031666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate daily GTV percentage\n",
        "trx['date'] = trx['transaction_time'].dt.date\n",
        "daily_gtv = trx.groupby(['date', 'user_id'])['gtv'].sum().reset_index()\n",
        "daily_total_gtv = trx.groupby('date')['gtv'].sum().reset_index(name='total_gtv')\n",
        "daily_gtv = pd.merge(daily_gtv, daily_total_gtv, on='date')\n",
        "daily_gtv['daily_gtv_percentage'] = daily_gtv['gtv'] / daily_gtv['total_gtv'] * 100\n",
        "avg_daily_gtv_percentage = daily_gtv.groupby('user_id')['daily_gtv_percentage'].mean().to_frame('avg_daily_gtv_percentage')\n",
        "\n",
        "print(avg_daily_gtv_percentage[:5])\n",
        "print(avg_daily_gtv_percentage['avg_daily_gtv_percentage'].max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jAIrvitVncp",
        "outputId": "44bdb135-2be7-4891-a797-d0a737c56994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         avg_daily_gtv_percentage\n",
            "user_id                          \n",
            "0                        0.000153\n",
            "1                        0.003412\n",
            "2                        0.000867\n",
            "3                        0.003553\n",
            "4                        0.000119\n",
            "5.402543659339173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CALCULATE AND MERGE SUMS\n",
        "\n",
        "# Group by user_id and asset_type, then sum the GTV\n",
        "gtv_by_asset_user = trx.groupby(['user_id', 'asset_type'])['gtv'].sum()\n",
        "\n",
        "# Unstack to create a DataFrame where each asset type is a column, and fill missing values with 0\n",
        "gtv_by_asset_user = gtv_by_asset_user.unstack(fill_value=0)\n",
        "\n",
        "# Rename the columns using a dictionary comprehension\n",
        "# The keys of the dictionary are the current column names (i.e., asset types)\n",
        "# and the values are the new column names in the format '{assetType}_sum'\n",
        "gtv_by_asset_user.columns = [f'{col}_sum' for col in gtv_by_asset_user.columns]\n",
        "\n",
        "# You can now merge this with your existing DataFrame 'profile' on 'user_id'\n",
        "profile = profile.merge(gtv_by_asset_user, on='user_id', how='left', suffixes=('', '_total_gtv'))"
      ],
      "metadata": {
        "id": "IIi8wFFfVnkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all the metrics\n",
        "metrics = [trx_counts, gtv_stats, avg_time_diff, avg_daily_gtv_percentage]\n",
        "for metric in metrics:\n",
        "    profile = profile.merge(metric, on='user_id', how='left')\n",
        "\n",
        "\n",
        "# Display the enriched profile DataFrame\n",
        "print(profile.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3w8cRXnlVyvt",
        "outputId": "514ed5f4-3a3e-41aa-ae18-bba40e5ebb84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   user_id mobile_brand_name mobile_marketing_name  age_in_year gender_name  \\\n",
            "0    53058              POCO             m3 pro 5g         45.0        Male   \n",
            "1    74136             Nokia                     3         52.0        Male   \n",
            "2   159548              POCO             m3 pro 5g         52.0      Female   \n",
            "3   156814           OnePlus                     8         62.0        Male   \n",
            "4   122581                LG              g7 thinq         48.0      Female   \n",
            "\n",
            "  marital_status education_background income_level occupation   crypto_sum  \\\n",
            "0            NaN                  NaN          NaN        NaN  1117.446429   \n",
            "1            NaN                  NaN          NaN        NaN     0.000000   \n",
            "2            NaN                  NaN          NaN        NaN     0.000000   \n",
            "3            NaN                  NaN          NaN        NaN     0.000000   \n",
            "4            NaN                  NaN          NaN        NaN     0.000000   \n",
            "\n",
            "   ...  idss  mfund  total_transactions  average_GTV   median_GTV  \\\n",
            "0  ...     0      0                   9   124.160714   112.626786   \n",
            "1  ...     0      0                  60    25.113244    32.552679   \n",
            "2  ...     0      0                   3  1243.020238  1791.260714   \n",
            "3  ...     0      0                   2   912.015179   912.015179   \n",
            "4  ...     0      0                   2  1007.498214  1007.498214   \n",
            "\n",
            "       max_GTV     min_GTV  max_minus_median_GTV  \\\n",
            "0   171.757143  100.941071             59.130357   \n",
            "1    34.001786   16.280357              1.449107   \n",
            "2  1905.230357   32.569643            113.969643   \n",
            "3  1791.457143   32.573214            879.441964   \n",
            "4  1811.803571  203.192857            804.305357   \n",
            "\n",
            "   avg_time_between_transactions  avg_daily_gtv_percentage  \n",
            "0                    4629.911315                  0.001512  \n",
            "1                    1465.744746                  0.000149  \n",
            "2                    8214.714067                  0.010901  \n",
            "3                       0.408083                  0.006439  \n",
            "4                       1.421383                  0.015342  \n",
            "\n",
            "[5 rows x 33 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming trx and profile are your DataFrames\n",
        "\n",
        "# Filter for SELL transactions and sum GTV per user_id\n",
        "total_gtv_sell = trx[trx['transaction_type'] == 'SELL'].groupby('user_id')['gtv'].sum().reset_index(name='total_gtv_sell')\n",
        "\n",
        "# Filter for BUY transactions and sum GTV per user_id\n",
        "total_gtv_buy = trx[trx['transaction_type'] == 'BUY'].groupby('user_id')['gtv'].sum().reset_index(name='total_gtv_buy')\n",
        "\n",
        "# Merge the summaries back into the profile DataFrame\n",
        "profile = profile.merge(total_gtv_sell, on='user_id', how='left')\n",
        "profile = profile.merge(total_gtv_buy, on='user_id', how='left')\n",
        "\n",
        "# Fill NaN values with 0 for users with no SELL or BUY transactions\n",
        "profile['total_gtv_sell'].fillna(0, inplace=True)\n",
        "profile['total_gtv_buy'].fillna(0, inplace=True)\n",
        "\n",
        "# Display the updated profile DataFrame\n",
        "print(profile.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLELGqKmiwJU",
        "outputId": "49dbc071-fbe4-4bc5-fa72-96cc543339dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   user_id mobile_brand_name mobile_marketing_name  age_in_year gender_name  \\\n",
            "0    53058              POCO             m3 pro 5g         45.0        Male   \n",
            "1    74136             Nokia                     3         52.0        Male   \n",
            "2   159548              POCO             m3 pro 5g         52.0      Female   \n",
            "3   156814           OnePlus                     8         62.0        Male   \n",
            "4   122581                LG              g7 thinq         48.0      Female   \n",
            "\n",
            "  marital_status education_background income_level occupation   crypto_sum  \\\n",
            "0            NaN                  NaN          NaN        NaN  1117.446429   \n",
            "1            NaN                  NaN          NaN        NaN     0.000000   \n",
            "2            NaN                  NaN          NaN        NaN     0.000000   \n",
            "3            NaN                  NaN          NaN        NaN     0.000000   \n",
            "4            NaN                  NaN          NaN        NaN     0.000000   \n",
            "\n",
            "   ...  total_transactions  average_GTV   median_GTV      max_GTV     min_GTV  \\\n",
            "0  ...                   9   124.160714   112.626786   171.757143  100.941071   \n",
            "1  ...                  60    25.113244    32.552679    34.001786   16.280357   \n",
            "2  ...                   3  1243.020238  1791.260714  1905.230357   32.569643   \n",
            "3  ...                   2   912.015179   912.015179  1791.457143   32.573214   \n",
            "4  ...                   2  1007.498214  1007.498214  1811.803571  203.192857   \n",
            "\n",
            "   max_minus_median_GTV  avg_time_between_transactions  \\\n",
            "0             59.130357                    4629.911315   \n",
            "1              1.449107                    1465.744746   \n",
            "2            113.969643                    8214.714067   \n",
            "3            879.441964                       0.408083   \n",
            "4            804.305357                       1.421383   \n",
            "\n",
            "   avg_daily_gtv_percentage  total_gtv_sell  total_gtv_buy  \n",
            "0                  0.001512      487.589286     629.857143  \n",
            "1                  0.000149        0.000000    1506.794643  \n",
            "2                  0.010901        0.000000    3729.060714  \n",
            "3                  0.006439        0.000000    1824.030357  \n",
            "4                  0.015342        0.000000    2014.996429  \n",
            "\n",
            "[5 rows x 35 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "profile.fillna({\n",
        "    'total_transactions': 0, 'sell_flag': 0, 'buy_flag': 0, 'crypto': 0,\n",
        "    'gold': 0, 'fx': 0, 'gss': 0, 'stock_index': 0,\n",
        "    'idss': 0, 'mfund': 0,\n",
        "}, inplace=True)"
      ],
      "metadata": {
        "id": "THlcdwYGiWQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "profile.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rOaL2lzVy3i",
        "outputId": "52d636c9-f184-49d7-b685-893fbef49519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['user_id', 'mobile_brand_name', 'mobile_marketing_name', 'age_in_year',\n",
              "       'gender_name', 'marital_status', 'education_background', 'income_level',\n",
              "       'occupation', 'crypto_sum', 'fx_sum', 'gold_sum', 'gss_sum', 'idss_sum',\n",
              "       'mfund_sum', 'stock_index_sum', 'sell_flag', 'buy_flag', 'crypto',\n",
              "       'gold', 'fx', 'gss', 'stock_index', 'idss', 'mfund',\n",
              "       'total_transactions', 'average_GTV', 'median_GTV', 'max_GTV', 'min_GTV',\n",
              "       'max_minus_median_GTV', 'avg_time_between_transactions',\n",
              "       'avg_daily_gtv_percentage', 'total_gtv_sell', 'total_gtv_buy'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_df = profile.copy()"
      ],
      "metadata": {
        "id": "7JPFUl5cVy_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def create_conditional_text(df, col, sentence):\n",
        "    \"\"\"\n",
        "    Creates a new column with a conditional sentence based on the presence of NaN in the specified column.\n",
        "\n",
        "    Parameters:\n",
        "    - df: DataFrame to modify.\n",
        "    - col: Column to check for NaN.\n",
        "    - sentence: Sentence pattern to use if the column value is not NaN.\n",
        "\n",
        "    Returns:\n",
        "    - Series with the constructed sentence or and empty string.\n",
        "    \"\"\"\n",
        "    return df.apply(lambda row: sentence.format(row[col]) if pd.notna(row[col]) else \"\", axis=1)\n",
        "\n",
        "# Define the sentence patterns for each column\n",
        "sentence_patterns = [\n",
        "    {'column': 'mobile_brand_name', 'text': \"mobile brand name {}.\"},\n",
        "    {'column': 'mobile_marketing_name', 'text': \"mobile marketing campaign {}.\"},\n",
        "    {'column': 'age_in_year', 'text': \"{} years old.\"},\n",
        "    {'column':'gender_name', 'text':\"gender {} .\"},\n",
        "    {'column':'marital_status', 'text':\"marital status {} .\"},\n",
        "    {'column':'education_background', 'text':\"education background {}.\"},\n",
        "    {'column':'income_level', 'text':\"Income level {}.\"},\n",
        "    {'column':'occupation', 'text':\"occupation {}.\"},\n",
        "    {'column':'crypto_sum', 'text':\"{}$ crypto investments.\"},\n",
        "    {'column':'crypto', 'text':\"{} crypto transactions.\"},\n",
        "    {'column':'fx_sum', 'text':\"{}$ fx assets investment.\"},\n",
        "    {'column':'fx', 'text':\"{} fx assets transactions.\"},\n",
        "    {'column':'gold_sum', 'text':\"{}$ gold investment.\"},\n",
        "    {'column':'gold', 'text':\"{} gold transactions.\"},\n",
        "    {'column':'gss_sum', 'text':\"{}$ green, social or sustainable (GSS) assets investment.\"},\n",
        "    {'column':'gss', 'text':\"{} social or sustainable (GSS) assets transactions.\"},\n",
        "    {'column':'idss_sum', 'text':\"{}$ in Intraday Short Selling (IDSS) securities investment.\"},\n",
        "    {'column':'idss', 'text':\"{} Intraday Short Selling (IDSS) transactions.\"},\n",
        "    {'column':'mfund_sum', 'text':\"{}$ mutual funds investment.\"},\n",
        "    {'column':'mfund', 'text':\"{} mutual funds transactions.\"},\n",
        "    {'column':'stock_index_sum', 'text':\"{}$ in index stocks investment.\"},\n",
        "    {'column':'stock_index', 'text':\"{} index stock transactions.\"},\n",
        "    {'column':'total_transactions', 'text':\"{} total transactions.\"},\n",
        "    {'column':'sell_flag', 'text':\"{} SELL transactions.\"},\n",
        "    {'column':'total_gtv_sell', 'text':\"{}$ SELL transactions.\"},\n",
        "    {'column':'buy_flag', 'text':\"{} BUY transactions.\"},\n",
        "    {'column':'total_gtv_buy', 'text':\"{}$ BUY transactions.\"},\n",
        "    {'column':'average_GTV', 'text':\"{}$ average gross transaction value transactions.\"},\n",
        "    {'column':'median_GTV', 'text':\"{}$ median gross transaction value transactions.\"},\n",
        "    {'column':'max_GTV', 'text':\"{}$ highest gross transaction value.\"},\n",
        "    {'column':'max_minus_median_GTV', 'text':\"The difference in $ between my transaction with the highest gross transaction value and the median gross transaction value of all my transactions was {}$.\"},\n",
        "    {'column':'avg_time_between_transactions', 'text':\"On average, I do a transaction every {} minutes.\"}\n",
        "    ]\n",
        "\n",
        "# Loop through each pattern and apply the function\n",
        "for pattern in sentence_patterns:\n",
        "    col = pattern['column']\n",
        "    text_col = 'text_' + col  # Construct the name for the new text column\n",
        "    sentence = pattern['text']\n",
        "    text_df[text_col] = create_conditional_text(text_df, col, sentence)\n"
      ],
      "metadata": {
        "id": "m0B3uEblt4X_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0lIAp6tYsxv",
        "outputId": "2bd7aa59-c193-42d7-e5e1-fc8beb71c517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['user_id', 'mobile_brand_name', 'mobile_marketing_name', 'age_in_year',\n",
              "       'gender_name', 'marital_status', 'education_background', 'income_level',\n",
              "       'occupation', 'crypto_sum', 'fx_sum', 'gold_sum', 'gss_sum', 'idss_sum',\n",
              "       'mfund_sum', 'stock_index_sum', 'sell_flag', 'buy_flag', 'crypto',\n",
              "       'gold', 'fx', 'gss', 'stock_index', 'idss', 'mfund',\n",
              "       'total_transactions', 'average_GTV', 'median_GTV', 'max_GTV', 'min_GTV',\n",
              "       'max_minus_median_GTV', 'avg_time_between_transactions',\n",
              "       'avg_daily_gtv_percentage', 'total_gtv_sell', 'total_gtv_buy',\n",
              "       'text_mobile_brand_name', 'text_mobile_marketing_name',\n",
              "       'text_age_in_year', 'text_gender_name', 'text_marital_status',\n",
              "       'text_education_background', 'text_income_level', 'text_occupation',\n",
              "       'text_crypto_sum', 'text_crypto', 'text_fx_sum', 'text_fx',\n",
              "       'text_gold_sum', 'text_gold', 'text_gss_sum', 'text_gss',\n",
              "       'text_idss_sum', 'text_idss', 'text_mfund_sum', 'text_mfund',\n",
              "       'text_stock_index_sum', 'text_stock_index', 'text_total_transactions',\n",
              "       'text_sell_flag', 'text_total_gtv_sell', 'text_buy_flag',\n",
              "       'text_total_gtv_buy', 'text_average_GTV', 'text_median_GTV',\n",
              "       'text_max_GTV', 'text_max_minus_median_GTV',\n",
              "       'text_avg_time_between_transactions'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select columns that start with 'text'\n",
        "text_columns = [col for col in text_df.columns if col.startswith('text')]\n",
        "\n",
        "# Concatenate the values of these columns into a new column\n",
        "text_df['user_description'] = text_df[text_columns].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
        "\n",
        "# Display the DataFrame to check the new column\n",
        "print(text_df[['user_id', 'user_description']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLiHRFJ6Ys5v",
        "outputId": "79c3f439-6750-4a62-cbf8-8b1103afae1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   user_id                                   user_description\n",
            "0    53058  mobile brand name POCO. mobile marketing campa...\n",
            "1    74136  mobile brand name Nokia. mobile marketing camp...\n",
            "2   159548  mobile brand name POCO. mobile marketing campa...\n",
            "3   156814  mobile brand name OnePlus. mobile marketing ca...\n",
            "4   122581  mobile brand name LG. mobile marketing campaig...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_df['user_description'].iloc[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1Trx_TBYtJQ",
        "outputId": "8c793cbf-a14b-43d3-e3c9-7fe0577fe492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mobile brand name POCO. mobile marketing campaign m3 pro 5g. 45.0 years old. gender Male .     1117.4464285714287$ crypto investments. 9 crypto transactions. 0.0$ fx assets investment. 0 fx assets transactions. 0.0$ gold investment. 0 gold transactions. 0.0$ green, social or sustainable (GSS) assets investment. 0 social or sustainable (GSS) assets transactions. 0.0$ in Intraday Short Selling (IDSS) securities investment. 0 Intraday Short Selling (IDSS) transactions. 0.0$ mutual funds investment. 0 mutual funds transactions. 0.0$ in index stocks investment. 0 index stock transactions. 9 total transactions. 4 SELL transactions. 487.5892857142858$ SELL transactions. 5 BUY transactions. 629.8571428571429$ BUY transactions. 124.16071428571429$ average gross transaction value transactions. 112.6267857142857$ median gross transaction value transactions. 171.75714285714287$ highest gross transaction value. The difference in $ between my transaction with the highest gross transaction value and the median gross transaction value of all my transactions was 59.130357142857164$. On average, I do a transaction every 4629.9113145833335 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_df = text_df.merge(train_label, on='user_id', how='left')"
      ],
      "metadata": {
        "id": "E-xuP9u0tGKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = text_df[['user_description','tgt']].copy()\n",
        "\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "hGzqlaTutaA8",
        "outputId": "3b58c59c-4c27-4bdb-99ab-4678b4df379f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         user_description  tgt\n",
              "0       mobile brand name POCO. mobile marketing campa...  1.0\n",
              "1       mobile brand name Nokia. mobile marketing camp...  1.0\n",
              "2       mobile brand name POCO. mobile marketing campa...  0.0\n",
              "3       mobile brand name OnePlus. mobile marketing ca...  1.0\n",
              "4       mobile brand name LG. mobile marketing campaig...  0.0\n",
              "...                                                   ...  ...\n",
              "188422  mobile brand name Samsung. mobile marketing ca...  1.0\n",
              "188423  mobile brand name Samsung. mobile marketing ca...  1.0\n",
              "188424  mobile brand name Samsung. mobile marketing ca...  0.0\n",
              "188425  mobile brand name Samsung. mobile marketing ca...  0.0\n",
              "188426  mobile brand name Samsung. mobile marketing ca...  0.0\n",
              "\n",
              "[188427 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c8dd1c37-324e-42bb-803b-b1b4abe9af38\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_description</th>\n",
              "      <th>tgt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mobile brand name POCO. mobile marketing campa...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mobile brand name Nokia. mobile marketing camp...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mobile brand name POCO. mobile marketing campa...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mobile brand name OnePlus. mobile marketing ca...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mobile brand name LG. mobile marketing campaig...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188422</th>\n",
              "      <td>mobile brand name Samsung. mobile marketing ca...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188423</th>\n",
              "      <td>mobile brand name Samsung. mobile marketing ca...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188424</th>\n",
              "      <td>mobile brand name Samsung. mobile marketing ca...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188425</th>\n",
              "      <td>mobile brand name Samsung. mobile marketing ca...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188426</th>\n",
              "      <td>mobile brand name Samsung. mobile marketing ca...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>188427 rows  2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8dd1c37-324e-42bb-803b-b1b4abe9af38')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c8dd1c37-324e-42bb-803b-b1b4abe9af38 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c8dd1c37-324e-42bb-803b-b1b4abe9af38');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a76b88ce-27d7-458b-a490-5e3950d8b2b2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a76b88ce-27d7-458b-a490-5e3950d8b2b2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a76b88ce-27d7-458b-a490-5e3950d8b2b2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_c2b282be-16e8-463e-a121-924f36ad898b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c2b282be-16e8-463e-a121-924f36ad898b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT"
      ],
      "metadata": {
        "id": "em6YMmkVwuni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2Im7OTNtnu0",
        "outputId": "c1721ca0-8431-49fa-f863-2b75eca9a392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU available, using the CPU instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDmDiygzx2Lr",
        "outputId": "9edfb56a-1c0f-41f5-b4d1-f5a0a7e51929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cloud-tpu-client torch-xla\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_OTB0xnzsdx",
        "outputId": "ee4df721-fb85-49f9-a969-245bc1691f35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cloud-tpu-client in /usr/local/lib/python3.10/dist-packages (0.10)\n",
            "Requirement already satisfied: torch-xla in /usr/local/lib/python3.10/dist-packages (2.2.0+libtpu)\n",
            "Requirement already satisfied: google-api-python-client==1.8.0 in /usr/local/lib/python3.10/dist-packages (from cloud-tpu-client) (1.8.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from cloud-tpu-client) (4.1.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.22.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.2.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.34.1)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.16.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (3.0.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from torch-xla) (1.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from torch-xla) (6.0.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->cloud-tpu-client) (0.6.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->cloud-tpu-client) (0.4.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->cloud-tpu-client) (4.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.63.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.20.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (5.3.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.9.2->google-api-python-client==1.8.0->cloud-tpu-client) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n"
      ],
      "metadata": {
        "id": "50xoIdYwzvrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "# Load the pretrained BERT model\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=2,\n",
        ")\n",
        "\n",
        "# Acquire the current TPU core as device\n",
        "device = xm.xla_device()\n",
        "\n",
        "# Move the model to the TPU device\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58WecPolx2Zl",
        "outputId": "40c2f395-a8f5-411f-a9a6-0b771ed6a810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ErJrHFl7x2gV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Parameters"
      ],
      "metadata": {
        "id": "MzBWhHjIyDZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Larger batch sizes tend to be better, and we can fit this in memory.\n",
        "batch_size = 32\n",
        "\n",
        "# I used a smaller learning rate to combat over-fitting that I was seeing in the\n",
        "# validation loss. I could probably try even smaller.\n",
        "learning_rate = 1e-5\n",
        "\n",
        "# Number of training epochs.\n",
        "epochs = 4"
      ],
      "metadata": {
        "id": "DkDvytiox2oX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# Initialize the maximum sentence length.\n",
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in df['user_description']:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length in `user_description`: ', max_len)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDSNS_en0lFA",
        "outputId": "e6ebca49-4168-4288-cc39-88864385ec84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n",
            "Max sentence length in `user_description`:  362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's use a maximum length of 200.\n",
        "max_len = 362"
      ],
      "metadata": {
        "id": "-ZXPByPQyFiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenize and Encode"
      ],
      "metadata": {
        "id": "kACyIFRCyf_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "print('Encoding all user descriptions in the dataset...')\n",
        "\n",
        "# For every description...\n",
        "for sent in df['user_description']:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens=True,   # Add '[CLS]' and '[SEP]'\n",
        "                        max_length=max_len,        # Pad & truncate all sentences.\n",
        "                        truncation=True,\n",
        "                        padding='max_length',\n",
        "                        return_attention_mask=True,# Construct attn. masks.\n",
        "                        return_tensors='pt',       # Return pytorch tensors.\n",
        "                )\n",
        "\n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "print('DONE.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3A6ihqIyFn-",
        "outputId": "ad603ffc-557a-4b3f-d649-2e1d93afa681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n",
            "Encoding all user descriptions in the dataset...\n",
            "DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "vKAeaMPz2NgC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Up"
      ],
      "metadata": {
        "id": "LuIwdmkm2UeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# First, we'll separate the rows with non-null target values for training the model\n",
        "# and the rows with null target values for later prediction.\n",
        "mask = df['tgt'].notnull()\n",
        "\n",
        "# Separate the dataframe into data for training and for prediction\n",
        "df_train = df[mask]\n",
        "df_predict = df[~mask]\n",
        "\n",
        "# Convert the 'tgt' column in the training dataframe to a tensor\n",
        "labels = torch.tensor(df_train['tgt'].values)\n",
        "\n",
        "# Create the TensorDataset with input_ids, attention_masks, and labels for the training data\n",
        "# Note: We need to filter the input_ids and attention_masks to only include the ones corresponding to the non-null 'tgt' values\n",
        "dataset = TensorDataset(input_ids[mask], attention_masks[mask], labels)\n",
        "\n",
        "# Define the size of the splits: train and validation\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Perform the split\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(len(train_dataset)))\n",
        "print('{:>5,} validation samples'.format(len(val_dataset)))\n",
        "\n",
        "# We will save the indices of the rows with null 'tgt' for later use\n",
        "predict_indices = df.index[~mask].tolist()\n",
        "\n",
        "# The prediction dataset only includes the input_ids and attention_masks, without labels, for the rows with null 'tgt'\n",
        "predict_dataset = TensorDataset(input_ids[~mask], attention_masks[~mask])\n",
        "\n",
        "print('{:>5,} prediction samples'.format(len(predict_dataset)))\n",
        "# Output the first few prediction indices as a check\n",
        "predict_indices[:5]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMhRsYJa2dox",
        "outputId": "e1ec79c6-0bc7-4cd8-9e74-a42245d15a64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "135,666 training samples\n",
            "15,075 validation samples\n",
            "37,686 prediction samples\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7, 9, 11, 12, 13]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Create the DataLoader for the training set. DataLoaders are used to shuffle the data and create batches.\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,  # The TensorDataset created earlier for training\n",
        "    sampler=RandomSampler(train_dataset),  # Sampling strategy is random to shuffle the data\n",
        "    batch_size=batch_size  # The batch size\n",
        ")\n",
        "\n",
        "# Create the DataLoader for the validation set. Typically, you don't need to shuffle the validation data.\n",
        "validation_dataloader = DataLoader(\n",
        "    val_dataset,  # The TensorDataset created earlier for validation\n",
        "    sampler=SequentialSampler(val_dataset),  # Sampling strategy is sequential as order doesn't matter for validation\n",
        "    batch_size=batch_size  # The batch size\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "zhIz7SNfx2wZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "G64rS-oK5cSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = learning_rate,\n",
        "                  eps = 1e-8\n",
        "                )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNZQ6OcR5eLs",
        "outputId": "583a2909-822c-4ed5-8d9b-489e879e7843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs].\n",
        "# (Note that this is not the same as the number of training samples!)\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "lphSUv_W5k2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "P33lfTqa5oM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "tX2Dq4PJ5uyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Install PyTorch/XLA\n",
        "!pip install cloud-tpu-client torch_xla"
      ],
      "metadata": {
        "id": "aZ75DZmPGXUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch_xla.core.xla_model as xm\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "for param in model.bert.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "\n",
        "torch.manual_seed(seed_val)\n",
        "\n",
        "#torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Imports\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "\n",
        "# Create a device object for TPU\n",
        "device = xm.xla_device()\n",
        "\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss,\n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# Wrap your DataLoader with ParallelLoader\n",
        "train_dataloader = pl.ParallelLoader(train_dataloader, [device]).per_device_loader(device)\n",
        "validation_dataloader = pl.ParallelLoader(validation_dataloader, [device]).per_device_loader(device)\n",
        "\n",
        "global_batch_size = batch_size\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # ParallelLoader creates a new DataLoader for each device\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids, b_input_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        model.zero_grad()\n",
        "        result = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels, return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Replace optimizer.step() with xm.optimizer_step(optimizer)\n",
        "        # This ensures compatibility with TPUs.\n",
        "        xm.optimizer_step(optimizer, barrier=True)  # Barrier ensures all cores wait for each other\n",
        "\n",
        "        # Update the learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        # `xm.xla_device()` returns the current device (TPU core) this process is using.\n",
        "        device = xm.xla_device()\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            result = model(b_input_ids,\n",
        "                          token_type_ids=None,\n",
        "                          attention_mask=b_input_mask,\n",
        "                          labels=b_labels,\n",
        "                          return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        # Accumulate the validation loss. Use `xm.mesh_reduce` to aggregate loss values across all TPU cores.\n",
        "        total_eval_loss += xm.mesh_reduce('total_eval_loss', loss.item(), lambda x: sum(x))\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        total_eval_accuracy += xm.mesh_reduce('total_eval_accuracy', flat_accuracy(logits, label_ids), lambda x: sum(x))\n",
        "\n",
        "\n",
        "    # Calculate global average validation loss and accuracy.\n",
        "    avg_val_loss = total_eval_loss / (len(validation_dataloader) * global_batch_size)\n",
        "    avg_val_accuracy = total_eval_accuracy / (len(validation_dataloader) * global_batch_size)\n",
        "\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "metadata": {
        "id": "6r5Zji9I8rWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "CvizeBeG9bfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap (doesn't seem to work in Colab).\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "metadata": {
        "id": "4JqOu4I39cx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loss and Validation Loss\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3EhNYIXY9c95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Predictions to Test"
      ],
      "metadata": {
        "id": "gUB54_ys-yAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, SequentialSampler\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming predict_dataset is correctly defined as shown earlier\n",
        "prediction_sampler = DistributedSampler(predict_dataset, num_replicas=xm.xrt_world_size(), rank=xm.get_ordinal(), shuffle=False)\n",
        "prediction_dataloader = DataLoader(predict_dataset, sampler=prediction_sampler, batch_size=batch_size)\n",
        "\n",
        "print(f'Predicting labels for {len(predict_dataset):,} test sentences...')\n",
        "\n",
        "model.eval()\n",
        "predictions = []\n",
        "\n",
        "# Wrap your DataLoader with ParallelLoader for TPU compatibility\n",
        "predict_dataloader = pl.ParallelLoader(prediction_dataloader, [device]).per_device_loader(device)\n",
        "\n",
        "for batch in predict_dataloader:\n",
        "    b_input_ids, b_input_mask = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        result = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, return_dict=True)\n",
        "\n",
        "    logits = result.logits\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "\n",
        "    # Store predictions\n",
        "    predictions.append(logits)\n",
        "\n",
        "# Combine the results across all batches and select the index of the highest logit as the prediction\n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "print('DONE.')\n"
      ],
      "metadata": {
        "id": "J_-YuKiE9dE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure df_predict is in the same order as predictions\n",
        "assert len(df_predict) == len(flat_predictions), \"Mismatch between the number of predictions and the number of user IDs\"\n",
        "\n",
        "# Create a DataFrame with user_id and predictions\n",
        "submission_df = pd.DataFrame({\n",
        "    'user_id': df_predict.loc[predict_indices, 'user_id'].values,  # Assuming 'user_id' is a column in df_predict\n",
        "    'pred_proba': flat_predictions\n",
        "})\n",
        "\n",
        "# Save to CSV file\n",
        "submission_file_path = '/content/drive/My Drive/BT5153_Kaggle/predictions.csv'\n",
        "submission_df.to_csv(submission_file_path, index=False)\n",
        "\n",
        "print(f'Submission file saved to {submission_file_path}')\n"
      ],
      "metadata": {
        "id": "EweUvcl---Hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OTHER"
      ],
      "metadata": {
        "id": "rJDcWwz6v52Q"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xqIu8Uswfedo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def create_conditional_text(df, col, sentence):\n",
        "    \"\"\"\n",
        "    Creates a new column with a conditional sentence based on the presence of NaN in the specified column.\n",
        "    \n",
        "    Parameters:\n",
        "    - df: DataFrame to modify.\n",
        "    - col: Column to check for NaN.\n",
        "    - sentence: Sentence pattern to use if the column value is not NaN.\n",
        "    \n",
        "    Returns:\n",
        "    - Series with the constructed sentence or and empty string.\n",
        "    \"\"\"\n",
        "    return df.apply(lambda row: sentence.format(row[col]) if pd.notna(row[col]) else \"\", axis=1)\n",
        "\n",
        "# Define the sentence patterns for each column\n",
        "sentence_patterns = [\n",
        "    {'column': 'mobile_brand_name', 'text': \"My mobile brand name is {}.\"},\n",
        "    {'column': 'mobile_marketing_name', 'text': \"I am targeted by a mobile marketing campaign called {}.\"},\n",
        "    {'column': 'age_in_year', 'text': \"I am {} years old.\"},\n",
        "    {'column':'gender_name', 'text':\"My gender is {} .\"},\n",
        "    {'column':'marital_status', 'text':\"My marital status is {} .\"},\n",
        "    {'column':'education_background', 'text':\"I was educated until  {} level.\"},\n",
        "    {'column':'income_level', 'text':\"I earn a yearly $ amout of {}.\"},\n",
        "    {'column':'occupation', 'text':\"My occupation is  {}.\"},\n",
        "    {'column':'crypto_sum', 'text':\"I invested a total of {}$ in crypto assets.\"},\n",
        "    {'column':'crypto', 'text':\"I did a total of {} crypto transactions.\"},\n",
        "    {'column':'fx_sum', 'text':\"I invested a total of {}$ in fx assets.\"},\n",
        "    {'column':'fx', 'text':\"I did a total of {} fx transactions.\"},\n",
        "    {'column':'gold_sum', 'text':\"I invested a total of {}$ in gold assets.\"},\n",
        "    {'column':'gold', 'text':\"I did a total of {} gold transactions.\"},\n",
        "    {'column':'gss_sum', 'text':\"I invested a total of {}$ in green, social or sustainable (GSS) assets.\"},\n",
        "    {'column':'gss', 'text':\"I did a total of {} social or sustainable (GSS) assets transactions.\"},\n",
        "    {'column':'idss_sum', 'text':\"I invested a total of {}$ in Intraday Short Selling (IDSS) securities.\"},\n",
        "    {'column':'idss', 'text':\"I did a total of {} Intraday Short Selling (IDSS) transactions.\"},\n",
        "    {'column':'mfund_sum', 'text':\"I invested a total of {}$ in mutual funds.\"},\n",
        "    {'column':'mfund', 'text':\"I did a total of {} mutual funds transactions.\"},\n",
        "    {'column':'stock_index_sum', 'text':\"I invested a total of {}$ in index stocks.\"},\n",
        "    {'column':'stock_index', 'text':\"I did a total of {} index stock transactions.\"},\n",
        "    {'column':'total_transactions', 'text':\"I did a total of {} transactions.\"},\n",
        "    {'column':'sell_flag', 'text':\"I did a total of {} SELL transactions.\"},\n",
        "    {'column':'total_gtv_sell', 'text':\"I did SELL transactions for a total value of {}$.\"},\n",
        "    {'column':'buy_flag', 'text':\"I did a total of {} BUY transactions.\"},\n",
        "    {'column':'total_gtv_buy', 'text':\"I did BUY transactions for a total value of {}$.\"},\n",
        "    {'column':'average_GTV', 'text':\"The average gross transaction value of my transactions was {}$.\"},\n",
        "    {'column':'median_GTV', 'text':\"The median gross transaction value of my transactions was {}$.\"},\n",
        "    {'column':'max_GTV', 'text':\"My transaction with the highest gross transaction value had a value of {}$.\"},\n",
        "    {'column':'max_minus_median_GTV', 'text':\"The difference in $ between my transaction with the highest gross transaction value and the median gross transaction value of all my transactions was {}$.\"},\n",
        "    {'column':'avg_time_between_transactions', 'text':\"On average, I do a transaction every {} minutes.\"}\n",
        "    ]\n",
        "\n",
        "# Loop through each pattern and apply the function\n",
        "for pattern in sentence_patterns:\n",
        "    col = pattern['column']\n",
        "    text_col = 'text_' + col  # Construct the name for the new text column\n",
        "    sentence = pattern['text']\n",
        "    text_df[text_col] = create_conditional_text(text_df, col, sentence)\n"
      ],
      "metadata": {
        "id": "KuTClgYcIPUD"
      }
    }
  ]
}